# ğŸ“šâ€¯Blueprint de la aplicaciÃ³n *GexAI*

> Estructura inicial â€” pensada para crecer con nuevos algoritmos de IA y funcionar **tanto en consola como en Jupyter**.
>
> Todo el cÃ³digo y comandos de ejemplo estÃ¡n en **espaÃ±ol** para coincidir con tu flujo de trabajo.

---

## 1. Ãrbol de directorios propuesto

```text
gexai/
â”œâ”€ pyproject.toml          # Metadata y dependencias (Poetry / PEPâ€‘621)
â”œâ”€ README.md               # Instrucciones de uso rÃ¡pido
â”œâ”€ .env.example            # Variables sensibles (se copia a .env)
â”œâ”€ notebooks/              # Cuadernos Jupyter exploratorios
â”‚  â”œâ”€ 00_exploratorio.ipynb
â”‚  â””â”€ 01_pipeline_demo.ipynb
â”œâ”€ src/
â”‚  â””â”€ gexai/
â”‚     â”œâ”€ __init__.py
â”‚     â”œâ”€ cli.py            # Entrada TyperÂ â†’Â consola
â”‚     â”œâ”€ config.py         # Pydantic BaseSettings
â”‚     â”œâ”€ download.py       # YouTube y descargas generales
â”‚     â”œâ”€ audio.py          # ConversiÃ³n, cortes, silencios
â”‚     â”œâ”€ diarization.py    # LÃ³gica pyannote
â”‚     â”œâ”€ transcription.py  # LÃ³gica Whisper
â”‚     â”œâ”€ pipeline.py       # Orquestador alto nivel
â”‚     â””â”€ utils.py          # Helpers comunes
â””â”€ tests/
   â””â”€ test_transcription.py
```

### Â¿Por quÃ© asÃ­?

* **`src/` layout** evita conflictos de imports cuando instalas en editable (`pip install -e .`).
* **Typer** da un CLI elegante y autocompletado.
* **Pydantic** centraliza configuraciÃ³n (tokens, paths) y puede preguntar al usuario si algo falta.
* **Notebooks** importan directamente `from gexai import ...`, garantizando que lo que pruebes en Jupyter coincide con la librerÃ­a instalada.

---

## 2. `pyproject.toml` limpio y funcional (solo Poetry)

```toml
[tool.poetry]
name = "gexai"
version = "0.1.0"
description = "Pipeline for transcription, speaker diarization, and future AI tools"
authors = [ "Alex Just Rodriguez <alexjustdata@gmail.com>" ]
packages = [
  { include = "gexai", from = "src" }
]

[tool.poetry.dependencies]
python = "^3.10"
typer = { version = "^0.12", extras = ["all"] }
pydantic = "^2.7"
pydantic-settings = "^2.2"
rich = "^13.7"
tqdm = "^4.66"
openai-whisper = { git = "https://github.com/openai/whisper.git" }
pyannote-audio = "^3.3"
yt-dlp = "^2025.3"
pydub = "^0.25"
torchaudio = "2.1.0"
torch = "2.1.0"

[tool.poetry.scripts]
gexai = "gexai.cli:app"

[tool.poetry.group.dev.dependencies]
pytest = "^8.2"
black = "^24.3"
isort = "^5.13"
```

---

## 3. ConfiguraciÃ³n con Pydantic â€” `config.py`

```python
from __future__ import annotations
from pydantic_settings import BaseSettings
from pydantic import Field
from pathlib import Path

class Settings(BaseSettings):
    """Ajustes globales leÃ­dos de `.env`, variables de entorno o argumentos."""

    hf_token: str = Field(..., env="HF_TOKEN", description="Token de Hugging Face")
    data_dir: Path = Field(Path("data"), env="GEXAI_DATA_DIR")
    whisper_model: str = Field("small", env="WHISPER_MODEL")

    class Config:
        env_file = ".env"
        extra = "ignore"

settings = Settings()  # instancia Ãºnica reutilizable
```

...

---

## 4. Mejoras a `pipeline.py`

El mÃ³dulo `transcribe_pipeline` debe:

1. Detectar si la entrada es una URL de YouTube (`https://...`) o un archivo local (`.mp3`, `.mp4`, `.wav`, etc.).
2. Si es un enlace, descargar automÃ¡ticamente el audio con `yt-dlp` y guardar en una carpeta temporal.
3. Convertir cualquier archivo de entrada a `.wav` si es necesario.
4. Ejecutar Whisper sobre el archivo `.wav` y:

   * Guardar la transcripciÃ³n en `.json` (estructura completa Whisper),
   * Exportar los subtÃ­tulos `.srt`,
   * Crear un archivo `.txt` limpio solo con texto plano.
5. Mostrar mensajes claros y progresivos con `rich.print()` o `typer.echo()`:

   * Desde la detecciÃ³n de tipo de entrada,
   * Hasta cada paso de procesamiento,
   * Terminando con los mensajes de archivos guardados.
6. Guardar todo en una subcarpeta dentro de `data/`, nombrada con timestamp o nombre del vÃ­deo, por ejemplo:

   ```
   data/
   â”œâ”€ transcripciones/
   â”‚   â”œâ”€ youtube_sw3N0leUULg/
   â”‚   â”‚   â”œâ”€ audio.wav
   â”‚   â”‚   â”œâ”€ whisper.json
   â”‚   â”‚   â”œâ”€ subtitulos.srt
   â”‚   â”‚   â””â”€ texto_plano.txt
   ```
7. Si se indica `diarize=True`, lanzar tambiÃ©n el pipeline de diarizaciÃ³n y guardar:

   * TranscripciÃ³n etiquetada por hablante (`.json`),
   * Texto plano con nombres (por ejemplo: `SPEAKER 1: ...`),
   * Nuevos subtÃ­tulos por hablante (`.srt`).
8. Mostrar siempre la ruta **final** de cada archivo generado:

   ```
   [bold green]âœ” Guardado en: data/transcripciones/youtube_sw3N0leUULg/whisper.json[/]
   [bold green]âœ” Guardado en: data/transcripciones/youtube_sw3N0leUULg/subtitulos.srt[/]
   ```
